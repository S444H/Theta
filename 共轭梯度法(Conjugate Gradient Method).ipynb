{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 共轭梯度法（Conjugate Gradient Method,CG）"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5e6b0d9246ac3ad"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 引入问题\n",
    "> 解决线性系统：\n",
    "$$\n",
    "\\[\n",
    "A \\mathbf{x} = \\mathbf{b}\n",
    "\\]\n",
    "$$\n",
    "\n",
    "- $A\\in\\mathbb{R}^{n\\times n}$ 是一个对称正定矩阵（即 $\\(A = A^T\\)$，且 $\\(\\mathbf{z}^T A \\mathbf{z} > 0\\)$ 对所有非零 $\\(\\mathbf{z}\\)$ 成立）\n",
    "- $\\(\\mathbf{x}\\)$ 是待求解向量\n",
    "- $\\(\\mathbf{b}\\)$ 是已知向量\n",
    "\n",
    "> 等价于最小化二次型目标函数：\n",
    "$$\n",
    "\\[\n",
    "f(\\mathbf{x}) = \\frac{1}{2} \\mathbf{x}^T A \\mathbf{x} - \\mathbf{b}^T \\mathbf{x}\n",
    "\\]\n",
    "$$\n",
    "- 对称正定矩阵$\\(A\\)$，保证了其是一个 **二次型函数** ，在任意方向上都是一个 **单峰的抛物线（凸函数）**\n",
    "\n",
    "> 其梯度为：\n",
    "$$\n",
    "\\[\n",
    "\\nabla f(\\mathbf{x}) = A \\mathbf{x} - \\mathbf{b}\n",
    "\\]\n",
    "$$\n",
    "- 最优解满足 $\\(\\nabla f(\\mathbf{x}) = 0\\)$，也就是 $\\(A \\mathbf{x} = \\mathbf{b}\\)$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ad03a81029761fc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 梯度下降法的缺陷\n",
    "\n",
    "> **传统梯度下降** 每步使用**负梯度方向**更新：\n",
    "$$\n",
    "\\[\n",
    "\\mathbf{x}_{k+1} = \\mathbf{x}_k - \\alpha_k \\nabla f(\\mathbf{x}_k)\n",
    "\\]\n",
    "$$\n",
    "> 当 $\\(A\\)$ 的特征值差距较大（即条件数大）时，下降路径 **被拉扯为“之”字形**，收敛缓慢"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c86a737ab50bc9d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 共轭方向的思想\n",
    "\n",
    "> 选取一组关于对称正定矩阵 $A\\in\\mathbb{R}^{n\\times n}$ 共轭的**搜索方向向量**$(\\mathbf{p}_0,\\ldots,\\mathbf{p}_{n-1})$：\n",
    "$$\n",
    "\\[\n",
    "\\mathbf{p}_i^T A \\mathbf{p}_j = 0 \\quad , i \\ne j\n",
    "\\]\n",
    "$$\n",
    "- 对称正定矩阵 $\\(A\\)$ 是对向量空间进行一种“拉伸 + 转向”变换\n",
    "- 共轭 = 在变形空间$\\(A\\)$中的正交\n",
    "\n",
    "> 去更新参数：\n",
    "$$\\mathbf{x}_{k+1} = \\mathbf{x}_k + \\alpha_k \\mathbf{p}_k$$\n",
    "\n",
    "> 共轭梯度法中生成的 n 个**搜索方向向量**$(\\mathbf{p}_0,\\ldots,\\mathbf{p}_{n-1})$是**线性无关**的，它们构成了对称正定矩阵$\\(A\\)$下的**共轭基底**，又由于函数在任意方向上为一个 **凸函数** ，在每一次梯度下降都做到**一维最优化**，所以共轭梯度法**最多只需要 n 步**就能在该空间内找到最优解。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "786b7134c229906e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 共轭梯度法的推导:\n",
    "> 初始时：\n",
    "- 设初始点： $\\mathbf{x}_0$\n",
    "- 初始残差（负梯度）：$\\mathbf{r}_0 = \\mathbf{b} - A \\mathbf{x}_0 = - \\nabla f(\\mathbf{x}_0)$\n",
    "- 初始搜索方向：$\\mathbf{p}_0 = \\mathbf{r}_0$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "383303c8cfecf1e2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### 1.推导步长 $\\alpha_k$\n",
    "> 已知方向 $\\mathbf{p}_k$ ，为使函数 $f(\\mathbf{x})$ （第 $k$ 步）最小：$\\alpha_k = \\arg \\min_{\\alpha} f(\\mathbf{x}_k + \\alpha \\mathbf{p}_k)$\n",
    "\n",
    "> 首先对二次函数求导：\n",
    "$$\n",
    "\\frac{d}{d\\alpha} f(\\mathbf{x}_k + \\alpha \\mathbf{p}_k) = 0\n",
    "$$\n",
    "\n",
    "> 展开：\n",
    "$$\n",
    "\\nabla f(\\mathbf{x}_k + \\alpha \\mathbf{p}_k)^T \\mathbf{p}_k = 0\n",
    "$$\n",
    "\n",
    "> 又梯度\n",
    "$$\n",
    "\\nabla f(\\mathbf{x}_k + \\alpha \\mathbf{p}_k) = A(\\mathbf{x}_k + \\alpha \\mathbf{p}_k) - \\mathbf{b}\n",
    "$$\n",
    "\n",
    "> 所以：\n",
    "\n",
    "$$\n",
    "\\left(A(\\mathbf{x}_k + \\alpha \\mathbf{p}_k) - \\mathbf{b}\\right)^T \\mathbf{p}_k = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Rightarrow (A \\mathbf{x}_k - \\mathbf{b})^T \\mathbf{p}_k + \\alpha \\mathbf{p}_k^T A \\mathbf{p}_k = 0\n",
    "$$\n",
    "\n",
    "> 又\n",
    "$$\n",
    "A \\mathbf{x}_k - \\mathbf{b} = - \\mathbf{r}_k\n",
    "$$\n",
    "\n",
    "> 所以：\n",
    "$$\n",
    "-\\mathbf{r}_k^T \\mathbf{p}_k + \\alpha \\mathbf{p}_k^T A \\mathbf{p}_k = 0 \\Rightarrow \\alpha_k = \\frac{\\mathbf{r}_k^T \\mathbf{p}_k}{\\mathbf{p}_k^T A \\mathbf{p}_k}\n",
    "$$\n",
    "\n",
    "- 再更新解：$\\mathbf{x}_{k+1} = \\mathbf{x}_k + \\alpha_k \\mathbf{p}_k$\n",
    "- 再更新残差：$\\mathbf{r}_{k+1}=\\mathbf{b}-A\\mathbf{x}_{k+1}=\\mathbf{b}-A(\\mathbf{x}_k+\\alpha_k\\mathbf{p}_k)=\\mathbf{r}_k-\\alpha_kA\\mathbf{p}_k$\n",
    "\n",
    "#### 2.构造下一个搜索方向 $\\mathbf{p}_{k+1}$（核心）\n",
    "\n",
    "> 使得新方向与之前的方向共轭，即满足：\n",
    "$$\n",
    "\\mathbf{p}_{k+1}^T A \\mathbf{p}_j = 0 \\quad , \\quad j \\le k\n",
    "$$\n",
    "\n",
    "> 通常用以下公式构造（结合最新的梯度信息与之前的共轭方向）：\n",
    "$$\n",
    "\\mathbf{p}_{k+1} = \\mathbf{r}_{k+1} + \\beta_k \\mathbf{p}_k\n",
    "$$\n",
    "\n",
    "- 其中 $\\beta_k$ 是调整系数，保证新构造的方向与前一方向 $A$-共轭。\n",
    "\n",
    "$$(\\mathbf{r}_{k+1}+\\beta_k\\mathbf{p}_k)^TA\\mathbf{p}_k=0$$\n",
    "\n",
    "> 解得\n",
    "$$\\beta_k=-\\frac{\\mathbf{r}_{k+1}^TA\\mathbf{p}_k}{\\mathbf{p}_k^TA\\mathbf{p}_k}$$\n",
    "\n",
    "> 因为实际计算中$A\\in\\mathbb{R}^{n\\times n}$未知或计算代价高，所以使用**Fletcher–Reeves 形式的共轭梯度法**：\n",
    "$$\n",
    "\\beta_k = \\frac{\\mathbf{r}_{k+1}^T \\mathbf{r}_{k+1}}{\\mathbf{r}_k^T \\mathbf{r}_k}\n",
    "$$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "383079c1a17ae02f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "***当残差 $\\|\\mathbf{r}_k\\|$ 足够小** 或者 **达到预设最大迭代次数** 时梯度下降停止*，解出 **X**\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2d2ffc73d56c42c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
